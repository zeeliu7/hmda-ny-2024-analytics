{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MrY_Jduikjnl"
   },
   "outputs": [],
   "source": [
    "# Data source: https://ffiec.cfpb.gov/data-browser/data/2024?category=states\n",
    "# Data fields: https://ffiec.cfpb.gov/documentation/publications/loan-level-datasets/lar-data-fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF_87bqMa9OR",
    "outputId": "2645d254-fc48-48ac-cc44-f7a43260df0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6946/3950111826.py:3: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('state_NY.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('state_NY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueGs-M7ubB1Y",
    "outputId": "33981880-f615-4347-c2e1-70ae1fbc3173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383577, 99)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VSk2mu_eev1_"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['activity_year', 'lei', 'derived_msa-md', 'state_code', 'census_tract', 'total_loan_costs', 'total_points_and_fees',\n",
    "              'origination_charges', 'discount_points', 'lender_credits', 'prepayment_penalty_term', 'intro_rate_period',\n",
    "              'multifamily_affordable_units', 'applicant_credit_score_type', 'co-applicant_credit_score_type', 'submission_of_application',\n",
    "              'initially_payable_to_institution'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-EitHVcUl_Ql"
   },
   "outputs": [],
   "source": [
    "df = df[~df['derived_ethnicity'].isin(['Ethnicity Not Available'])]\n",
    "df = df[~df['derived_race'].isin(['Race Not Available'])]\n",
    "df = df[~df['derived_sex'].isin(['Sex Not Available'])]\n",
    "df = df[~df['loan_purpose'].astype(str).isin(['5'])]\n",
    "df = df[~df['hoepa_status'].astype(str).isin(['3'])]\n",
    "df = df[~df['manufactured_home_secured_property_type'].astype(str).isin(['3'])]\n",
    "df = df[~df['manufactured_home_land_property_interest'].astype(str).isin(['5'])]\n",
    "df = df[~df['applicant_age'].astype(str).isin(['8888'])]\n",
    "df = df[~df['co-applicant_age'].astype(str).isin(['8888'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CBRkXvO0te6a"
   },
   "outputs": [],
   "source": [
    "columns_require_1111_cleaning = ['reverse_mortgage', 'open-end_line_of_credit', 'business_or_commercial_purpose',\n",
    "                                 'manufactured_home_secured_property_type', 'manufactured_home_land_property_interest']\n",
    "columns_require_1111_cleaning.extend([f'aus-{i}' for i in range(1, 6)])\n",
    "columns_require_1111_cleaning.extend([f'denial_reason-{i}' for i in range(1, 5)])\n",
    "for col in columns_require_1111_cleaning:\n",
    "    df = df[~df[col].astype(str).isin(['1111'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tVIDRctT0UBh"
   },
   "outputs": [],
   "source": [
    "columns_require_exempt_cleaning = ['loan_to_value_ratio', 'interest_rate', 'rate_spread', 'loan_term', 'property_value',\n",
    "                                   'debt_to_income_ratio']\n",
    "for col in columns_require_exempt_cleaning:\n",
    "    df = df[~df[col].astype(str).isin(['Exempt'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qkcrO2-OhYqD"
   },
   "outputs": [],
   "source": [
    "# source: https://en.wikipedia.org/wiki/List_of_counties_in_New_York\n",
    "\n",
    "df['county_code'] = df['county_code'].astype(str).map({\n",
    "    \"36001\": \"Albany\",\n",
    "    \"36003\": \"Allegany\",\n",
    "    \"36005\": \"Bronx\",\n",
    "    \"36007\": \"Broome\",\n",
    "    \"36009\": \"Cattaraugus\",\n",
    "    \"36011\": \"Cayuga\",\n",
    "    \"36013\": \"Chautauqua\",\n",
    "    \"36015\": \"Chemung\",\n",
    "    \"36017\": \"Chenango\",\n",
    "    \"36019\": \"Clinton\",\n",
    "    \"36021\": \"Columbia\",\n",
    "    \"36023\": \"Cortland\",\n",
    "    \"36025\": \"Delaware\",\n",
    "    \"36027\": \"Dutchess\",\n",
    "    \"36029\": \"Erie\",\n",
    "    \"36031\": \"Essex\",\n",
    "    \"36033\": \"Franklin\",\n",
    "    \"36035\": \"Fulton\",\n",
    "    \"36037\": \"Genesee\",\n",
    "    \"36039\": \"Greene\",\n",
    "    \"36041\": \"Hamilton\",\n",
    "    \"36043\": \"Herkimer\",\n",
    "    \"36045\": \"Jefferson\",\n",
    "    \"36047\": \"Kings\",\n",
    "    \"36049\": \"Lewis\",\n",
    "    \"36051\": \"Livingston\",\n",
    "    \"36053\": \"Madison\",\n",
    "    \"36055\": \"Monroe\",\n",
    "    \"36057\": \"Montgomery\",\n",
    "    \"36059\": \"Nassau\",\n",
    "    \"36061\": \"New York\",\n",
    "    \"36063\": \"Niagara\",\n",
    "    \"36065\": \"Oneida\",\n",
    "    \"36067\": \"Onondaga\",\n",
    "    \"36069\": \"Ontario\",\n",
    "    \"36071\": \"Orange\",\n",
    "    \"36073\": \"Orleans\",\n",
    "    \"36075\": \"Oswego\",\n",
    "    \"36077\": \"Otsego\",\n",
    "    \"36079\": \"Putnam\",\n",
    "    \"36081\": \"Queens\",\n",
    "    \"36083\": \"Rensselaer\",\n",
    "    \"36085\": \"Richmond\",\n",
    "    \"36087\": \"Rockland\",\n",
    "    \"36089\": \"St. Lawrence\",\n",
    "    \"36091\": \"Saratoga\",\n",
    "    \"36093\": \"Schenectady\",\n",
    "    \"36095\": \"Schoharie\",\n",
    "    \"36097\": \"Schuyler\",\n",
    "    \"36099\": \"Seneca\",\n",
    "    \"36101\": \"Steuben\",\n",
    "    \"36103\": \"Suffolk\",\n",
    "    \"36105\": \"Sullivan\",\n",
    "    \"36107\": \"Tioga\",\n",
    "    \"36109\": \"Tompkins\",\n",
    "    \"36111\": \"Ulster\",\n",
    "    \"36113\": \"Warren\",\n",
    "    \"36115\": \"Washington\",\n",
    "    \"36117\": \"Wayne\",\n",
    "    \"36119\": \"Westchester\",\n",
    "    \"36121\": \"Wyoming\",\n",
    "    \"36123\": \"Yates\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9etQceJ3kBQj"
   },
   "outputs": [],
   "source": [
    "df['conforming_loan_limit'] = df['conforming_loan_limit'].map({\n",
    "    \"C\": \"Conforming\",\n",
    "    \"NC\": \"Nonconforming\",\n",
    "    \"U\": \"Undetermined\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1SgDqRPvn1ML"
   },
   "outputs": [],
   "source": [
    "df['action_taken'] = df['action_taken'].astype(str).map({\n",
    "    \"1\": \"Loan_originated\",\n",
    "    \"2\": \"Application_approved_but_not_accepted\",\n",
    "    \"3\": \"Application_denied\",\n",
    "    \"4\": \"Application_withdrawn_by_applicant\",\n",
    "    \"5\": \"File_closed_for_incompleteness\",\n",
    "    \"6\": \"Purchased_loan\",\n",
    "    \"7\": \"Preapproval_request_denied\",\n",
    "    \"8\": \"Preapproval_request_approved_but_not_accepted\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5-KdSB5Gox4m"
   },
   "outputs": [],
   "source": [
    "df['purchaser_type'] = df['purchaser_type'].astype(str).map({\n",
    "    \"0\": \"Not_applicable\",\n",
    "    \"1\": \"Fannie_Mae\",\n",
    "    \"2\": \"Ginnie_Mae\",\n",
    "    \"3\": \"Freddie_Mac\",\n",
    "    \"4\": \"Farmer_Mac\",\n",
    "    \"5\": \"Private_securitizer\",\n",
    "    \"6\": \"Commercial_bank_or_savings_bank_or_savings_association\",\n",
    "    \"71\": \"Credit_union_or_mortgage_company_or_finance_company\",\n",
    "    \"72\": \"Life_insurance_company\",\n",
    "    \"8\": \"Affiliate_institution\",\n",
    "    \"9\": \"Other_type_of_purchaser\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9_pW4jhorwtI"
   },
   "outputs": [],
   "source": [
    "df['loan_type'] = df['loan_type'].astype(str).map({\n",
    "    \"1\": \"Conventional\",\n",
    "    \"2\": \"FHA_insured\",\n",
    "    \"3\": \"VA_guaranteed\",\n",
    "    \"4\": \"RHS_or_FSA_guaranteed\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_6dS3uCZ4s9C"
   },
   "outputs": [],
   "source": [
    "df['occupancy_type'] = df['occupancy_type'].astype(str).map({\n",
    "    \"1\": \"Principal_residence\",\n",
    "    \"2\": \"Second_residence\",\n",
    "    \"3\": \"Investment_property\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TsmZbbPi7Tvx"
   },
   "outputs": [],
   "source": [
    "df['manufactured_home_secured_property_type'] = df['manufactured_home_secured_property_type'].astype(str).map({\n",
    "    \"1\": \"Manufactured_home_and_land\",\n",
    "    \"2\": \"Manufactured_home_and_not_land\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sNl6VqBa6BPw"
   },
   "outputs": [],
   "source": [
    "df['manufactured_home_land_property_interest'] = df['manufactured_home_land_property_interest'].astype(str).map({\n",
    "    \"1\": \"Direct_ownership\",\n",
    "    \"2\": \"Indirect_ownership\",\n",
    "    \"3\": \"Paid_leasehold\",\n",
    "    \"4\": \"Unpaid_leasehold\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oS8t5iBBOJLj"
   },
   "outputs": [],
   "source": [
    "df['applicant_sex'] = df['applicant_sex'].astype(str).map({\n",
    "    \"1\": \"Male\",\n",
    "    \"2\": \"Female\",\n",
    "    \"3\": \"Not_provided\",\n",
    "    \"4\": \"Not_applicable\",\n",
    "    \"6\": \"Both_selected\"\n",
    "})\n",
    "\n",
    "df['co-applicant_sex'] = df['co-applicant_sex'].astype(str).map({\n",
    "    \"1\": \"Male\",\n",
    "    \"2\": \"Female\",\n",
    "    \"3\": \"Not_provided\",\n",
    "    \"4\": \"Not_applicable\",\n",
    "    \"5\": \"No_co-applicant\",\n",
    "    \"6\": \"Both_selected\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jAjSZnwxD46P"
   },
   "outputs": [],
   "source": [
    "df['applicant_ethnicity_observed'] = df['applicant_ethnicity_observed'].astype(str).map({\n",
    "    \"1\": True,\n",
    "    \"2\": False,\n",
    "    \"3\": np.nan\n",
    "})\n",
    "\n",
    "df['co-applicant_ethnicity_observed'] = df['co-applicant_ethnicity_observed'].astype(str).map({\n",
    "    \"1\": True,\n",
    "    \"2\": False,\n",
    "    \"3\": np.nan,\n",
    "    \"4\": \"no_co-applicant\"\n",
    "})\n",
    "\n",
    "df['applicant_race_observed'] = df['applicant_race_observed'].astype(str).map({\n",
    "    \"1\": True,\n",
    "    \"2\": False,\n",
    "    \"3\": np.nan\n",
    "})\n",
    "\n",
    "df['co-applicant_race_observed'] = df['co-applicant_race_observed'].astype(str).map({\n",
    "    \"1\": True,\n",
    "    \"2\": False,\n",
    "    \"3\": np.nan,\n",
    "    \"4\": \"no_co-applicant\"\n",
    "})\n",
    "\n",
    "df['applicant_sex_observed'] = df['applicant_sex_observed'].astype(str).map({\n",
    "    \"1\": True,\n",
    "    \"2\": False,\n",
    "    \"3\": np.nan\n",
    "})\n",
    "\n",
    "df['co-applicant_sex_observed'] = df['co-applicant_sex_observed'].astype(str).map({\n",
    "    \"1\": True,\n",
    "    \"2\": False,\n",
    "    \"3\": np.nan,\n",
    "    \"4\": \"no_co-applicant\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UkncyHp9p9Rh"
   },
   "outputs": [],
   "source": [
    "def convert_to_boolean_and_drop(df, conversions_list):\n",
    "    for new_col, original_col, value_for_true in conversions_list:\n",
    "        df[new_col] = (df[original_col].astype(str) == value_for_true)\n",
    "        df = df.drop(original_col, axis=1)\n",
    "    return df\n",
    "\n",
    "boolean_conversions = [\n",
    "    ('preapproval_requested', 'preapproval', '1'),\n",
    "    ('secured_by_a_first_lien', 'lien_status', '1'),\n",
    "    ('is_reverse_mortgage', 'reverse_mortgage', '1'),\n",
    "    ('is_open-end_line_of_credit', 'open-end_line_of_credit', '1'),\n",
    "    ('primarily_for_a_business_or_commercial_purpose', 'business_or_commercial_purpose', '1'),\n",
    "    ('is_high_cost_mortgage', 'hoepa_status', '1'),\n",
    "    ('includes_negative_amortization', 'negative_amortization', '1'),\n",
    "    ('includes_interest_only_payment', 'interest_only_payment', '1'),\n",
    "    ('includes_balloon_payment', 'balloon_payment', '1'),\n",
    "    ('includes_other_nonamortizing_features', 'other_nonamortizing_features', '1'),\n",
    "    ('is_site_built', 'construction_method', '1')\n",
    "]\n",
    "df = convert_to_boolean_and_drop(df, boolean_conversions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3OcZM0PblZ2n"
   },
   "outputs": [],
   "source": [
    "columns_require_regex_cleaning = ['derived_loan_product_type', 'derived_dwelling_category', 'derived_ethnicity', 'derived_race', 'derived_sex']\n",
    "for col in columns_require_regex_cleaning:\n",
    "    df[col] = df[col].str.replace(r'[^a-zA-Z0-9\\-_]', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bW7d_cGW766u"
   },
   "outputs": [],
   "source": [
    "df['total_units'] = df['total_units'].replace({\">149\": \"over_149\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gIrA5LOxBXjx"
   },
   "outputs": [],
   "source": [
    "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace({'>60%': 'over_60_percent', '<20%': \"below_20_percent\"})\n",
    "df['debt_to_income_ratio'] = df['debt_to_income_ratio'].replace(r'%', '_percent', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9Nn62OzfQFL7"
   },
   "outputs": [],
   "source": [
    "df['applicant_age'] = df['applicant_age'].replace({'<25': 'below_25', '>74': \"above_74\"})\n",
    "df['co-applicant_age'] = df['co-applicant_age'].replace({'<25': 'below_25', '>74': \"above_74\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QKY7luPsHaLq"
   },
   "outputs": [],
   "source": [
    "ethnicity_map = {\n",
    "    '1': 'Hispanic_or_Latino',\n",
    "    '11': 'Mexican',\n",
    "    '12': 'Puerto_Rican',\n",
    "    '13': 'Cuban',\n",
    "    '14': 'Other_Hispanic_or_Latino',\n",
    "    '2': 'Not_Hispanic_or_Latino',\n",
    "    '3': 'Not_provided',\n",
    "    '4': 'Not_applicable',\n",
    "    '5': \"No_co-applicant\"\n",
    "}\n",
    "\n",
    "applicant_ethnicity_cols = [f'applicant_ethnicity-{i}' for i in range(1, 6)]\n",
    "\n",
    "df[applicant_ethnicity_cols] = df[applicant_ethnicity_cols].astype(str)\n",
    "\n",
    "for code, category in ethnicity_map.items():\n",
    "    col_name = f'applicant_ethnicity_is_{category}'\n",
    "    df[col_name] = df[applicant_ethnicity_cols].isin([code]).any(axis=1)\n",
    "\n",
    "df = df.drop(applicant_ethnicity_cols, axis=1)\n",
    "\n",
    "co_applicant_ethnicity_cols = [f'co-applicant_ethnicity-{i}' for i in range(1, 6)]\n",
    "\n",
    "df[co_applicant_ethnicity_cols] = df[co_applicant_ethnicity_cols].astype(str)\n",
    "\n",
    "for code, category in ethnicity_map.items():\n",
    "    col_name = f'co-applicant_ethnicity_is_{category}'\n",
    "    df[col_name] = df[co_applicant_ethnicity_cols].isin([code]).any(axis=1)\n",
    "\n",
    "df = df.drop(co_applicant_ethnicity_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vFqYfTBrFiet"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6946/2861567218.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[co_applicant_race_cols].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2861567218.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[co_applicant_race_cols].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2861567218.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[co_applicant_race_cols].isin([code]).any(axis=1)\n"
     ]
    }
   ],
   "source": [
    "race_map = {\n",
    "    '1': 'American_Indian_or_Alaska_Native',\n",
    "    '2': 'Asian',\n",
    "    '21': 'Asian_Indian',\n",
    "    '22': 'Chinese',\n",
    "    '23': 'Filipino',\n",
    "    '24': 'Japanese',\n",
    "    '25': 'Korean',\n",
    "    '26': 'Vietnamese',\n",
    "    '27': 'Other_Asian',\n",
    "    '3': 'Black_or_African_American',\n",
    "    '4': 'Native_Hawaiian_or_Other_Pacific_Islander',\n",
    "    '41': 'Native_Hawaiian',\n",
    "    '42': 'Guamanian_or_Chamorro',\n",
    "    '43': 'Samoan',\n",
    "    '44': 'Other_Pacific_Islander',\n",
    "    '5': 'White',\n",
    "    '6': 'Not_provided',\n",
    "    '7': 'Not_applicable',\n",
    "    '8': 'No_co-applicant'\n",
    "}\n",
    "\n",
    "applicant_race_cols = [f'applicant_race-{i}' for i in range(1, 6)]\n",
    "\n",
    "df[applicant_race_cols] = df[applicant_race_cols].astype(str)\n",
    "\n",
    "for code, category in race_map.items():\n",
    "    col_name = f'applicant_race_is_{category}'\n",
    "    df[col_name] = df[applicant_race_cols].isin([code]).any(axis=1)\n",
    "\n",
    "df = df.drop(applicant_race_cols, axis=1)\n",
    "\n",
    "co_applicant_race_cols = [f'co-applicant_race-{i}' for i in range(1, 6)]\n",
    "\n",
    "df[co_applicant_race_cols] = df[co_applicant_race_cols].astype(str)\n",
    "\n",
    "for code, category in race_map.items():\n",
    "    col_name = f'co-applicant_race_is_{category}'\n",
    "    df[col_name] = df[co_applicant_race_cols].isin([code]).any(axis=1)\n",
    "\n",
    "df = df.drop(co_applicant_race_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5vN3hUuxYtKB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6946/3201566146.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/3201566146.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/3201566146.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/3201566146.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/3201566146.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/3201566146.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/3201566146.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n"
     ]
    }
   ],
   "source": [
    "aus_map = {\n",
    "    '1': 'DU',\n",
    "    '2': 'LP_or_Loan_Product_Advisor',\n",
    "    '3': 'TOTAL_scorecard',\n",
    "    '4': 'GUS',\n",
    "    '5': 'Other',\n",
    "    '6': 'Not_applicable',\n",
    "    '7': 'Internal Proprietary System'\n",
    "}\n",
    "\n",
    "aus_rows = [f'aus-{i}' for i in range(1, 6)]\n",
    "\n",
    "df[aus_rows] = df[aus_rows].astype(str)\n",
    "\n",
    "for code, category in aus_map.items():\n",
    "    col_name = f'aus_is_{category}'\n",
    "    df[col_name] = df[aus_rows].isin([code]).any(axis=1)\n",
    "\n",
    "df = df.drop(aus_rows, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_11DL5KDbVEl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
      "/tmp/ipykernel_6946/2223689025.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n"
     ]
    }
   ],
   "source": [
    "denial_reason_map = {\n",
    "    '1': 'Debt-to-income_ratio',\n",
    "    '2': 'Employment_history',\n",
    "    '3': 'Credit_history',\n",
    "    '4': 'Collateral',\n",
    "    '5': 'Insufficient_cash',\n",
    "    '6': 'Unverifiable_information',\n",
    "    '7': 'Credit_application_incomplete',\n",
    "    '8': 'Mortgage_insurance_denied',\n",
    "    '9': 'Other',\n",
    "    '10': 'Not_applicable'\n",
    "}\n",
    "\n",
    "denial_reason_rows = [f'denial_reason-{i}' for i in range(1, 5)]\n",
    "\n",
    "df[denial_reason_rows] = df[denial_reason_rows].astype(str)\n",
    "\n",
    "for code, category in denial_reason_map.items():\n",
    "    col_name = f'denial_reason_is_{category}'\n",
    "    df[col_name] = df[denial_reason_rows].isin([code]).any(axis=1)\n",
    "\n",
    "df = df.drop(denial_reason_rows, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['county_code', 'conforming_loan_limit', 'loan_to_value_ratio', 'interest_rate', 'rate_spread', 'loan_term',\n",
    "                       'property_value', 'income', 'debt_to_income_ratio', 'applicant_age', 'co-applicant_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "28jFiXQFcKiO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 126)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "qS6jCwfUcLBP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [county_code, conforming_loan_limit, derived_loan_product_type, derived_dwelling_category, derived_ethnicity, derived_race, derived_sex, action_taken, purchaser_type, loan_type, loan_purpose, loan_amount, loan_to_value_ratio, interest_rate, rate_spread, loan_term, property_value, occupancy_type, manufactured_home_secured_property_type, manufactured_home_land_property_interest, total_units, income, debt_to_income_ratio, applicant_ethnicity_observed, co-applicant_ethnicity_observed, applicant_race_observed, co-applicant_race_observed, applicant_sex, co-applicant_sex, applicant_sex_observed, co-applicant_sex_observed, applicant_age, co-applicant_age, applicant_age_above_62, co-applicant_age_above_62, tract_population, tract_minority_population_percent, ffiec_msa_md_median_family_income, tract_to_msa_income_percentage, tract_owner_occupied_units, tract_one_to_four_family_homes, tract_median_age_of_housing_units, preapproval_requested, secured_by_a_first_lien, is_reverse_mortgage, is_open-end_line_of_credit, primarily_for_a_business_or_commercial_purpose, is_high_cost_mortgage, includes_negative_amortization, includes_interest_only_payment, includes_balloon_payment, includes_other_nonamortizing_features, is_site_built, applicant_ethnicity_is_Hispanic_or_Latino, applicant_ethnicity_is_Mexican, applicant_ethnicity_is_Puerto_Rican, applicant_ethnicity_is_Cuban, applicant_ethnicity_is_Other_Hispanic_or_Latino, applicant_ethnicity_is_Not_Hispanic_or_Latino, applicant_ethnicity_is_Not_provided, applicant_ethnicity_is_Not_applicable, applicant_ethnicity_is_No_co-applicant, co-applicant_ethnicity_is_Hispanic_or_Latino, co-applicant_ethnicity_is_Mexican, co-applicant_ethnicity_is_Puerto_Rican, co-applicant_ethnicity_is_Cuban, co-applicant_ethnicity_is_Other_Hispanic_or_Latino, co-applicant_ethnicity_is_Not_Hispanic_or_Latino, co-applicant_ethnicity_is_Not_provided, co-applicant_ethnicity_is_Not_applicable, co-applicant_ethnicity_is_No_co-applicant, applicant_race_is_American_Indian_or_Alaska_Native, applicant_race_is_Asian, applicant_race_is_Asian_Indian, applicant_race_is_Chinese, applicant_race_is_Filipino, applicant_race_is_Japanese, applicant_race_is_Korean, applicant_race_is_Vietnamese, applicant_race_is_Other_Asian, applicant_race_is_Black_or_African_American, applicant_race_is_Native_Hawaiian_or_Other_Pacific_Islander, applicant_race_is_Native_Hawaiian, applicant_race_is_Guamanian_or_Chamorro, applicant_race_is_Samoan, applicant_race_is_Other_Pacific_Islander, applicant_race_is_White, applicant_race_is_Not_provided, applicant_race_is_Not_applicable, applicant_race_is_No_co-applicant, co-applicant_race_is_American_Indian_or_Alaska_Native, co-applicant_race_is_Asian, co-applicant_race_is_Asian_Indian, co-applicant_race_is_Chinese, co-applicant_race_is_Filipino, co-applicant_race_is_Japanese, co-applicant_race_is_Korean, co-applicant_race_is_Vietnamese, co-applicant_race_is_Other_Asian, co-applicant_race_is_Black_or_African_American, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 126 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
